{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks with Pytorch\n",
    "\n",
    "Original Paper: https://arxiv.org/abs/1706.02216    \n",
    "Original Code: https://github.com/rusty1s/pytorch_geometric/blob/master/examples/reddit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.1-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-0.13.1-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch, torchvision, torchaudio\n",
      "  Running setup.py install for pytorch: started\n",
      "  Running setup.py install for pytorch: finished with status 'error'\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\wikid\\AppData\\Local\\Temp\\pip-install-4f0dj6qc\\pytorch_a6436af200eb47c990b57ba0773d91de\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for pytorch did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\wikid\\AppData\\Local\\Temp\\pip-install-4f0dj6qc\\pytorch_a6436af200eb47c990b57ba0773d91de\\setup.py\", line 11, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> pytorch\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch torchvision torchaudio\n",
    "!pip install torch_scatter\n",
    "!pip install torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "\n",
    "sys.path.append('./')\n",
    "from utils import *\n",
    "logger = make_logger(name='graphsage_logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://data.dgl.ai/dataset/reddit.zip\n",
      "Extracting c:\\Users\\wikid\\Desktop\\data\\Reddit\\raw\\reddit.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '..', 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:28:16,964 - graphsage_logger - Node Feature Matrix Info: # Nodes: 232965, # Node Features: 602\n",
      "2023-03-07 10:28:16,976 - graphsage_logger - Edge Index Shape: torch.Size([2, 114615892])\n",
      "2023-03-07 10:28:16,978 - graphsage_logger - Edge Weight: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153431\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Node Feature Matrix Info: # Nodes: {data.x.shape[0]}, # Node Features: {data.x.shape[1]}\")\n",
    "\n",
    "logger.info(f\"Edge Index Shape: {data.edge_index.shape}\")\n",
    "logger.info(f\"Edge Weight: {data.edge_attr}\")\n",
    "\n",
    "print(data.train_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n",
      "  warnings.warn(out)\n",
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:554: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 8 (`cpuset` is not taken into account), which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "# Define Sampler\n",
    "train_loader = NeighborSampler(\n",
    "    data.edge_index, node_idx=data.train_mask,\n",
    "    sizes=[25, 10], batch_size=1024, shuffle=True, num_workers=12)\n",
    "\n",
    "subgraph_loader = NeighborSampler(\n",
    "    data.edge_index, node_idx=None,\n",
    "    sizes=[-1], batch_size=1024, shuffle=False, num_workers=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-07 10:29:46,596 - graphsage_logger - Current Batch Size: 1024\n",
      "2023-03-07 10:29:46,600 - graphsage_logger - 현재 Subgraph에서 사용된 모든 node id의 개수: 106532\n",
      "2023-03-07 10:29:46,601 - graphsage_logger - Layer의 수: 2\n",
      "2023-03-07 10:29:46,603 - graphsage_logger - 진행 방향: 84747개의 2-hop neighbors ->20761개의 1-hop neighbors -> 1024개의 Head Nodes\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_id, adjs = next(iter(train_loader))\n",
    "\n",
    "logger.info(f\"Current Batch Size: {batch_size}\")\n",
    "logger.info(f\"현재 Subgraph에서 사용된 모든 node id의 개수: {n_id.shape[0]}\")\n",
    "logger.info(f\"Layer의 수: {len(adjs)}\")\n",
    "\n",
    "A = adjs[1].size[0] - batch_size\n",
    "B = adjs[0].size[0] - A - batch_size\n",
    "\n",
    "logger.info(f\"진행 방향: {B}개의 2-hop neighbors ->\"\n",
    "            f\"{A}개의 1-hop neighbors -> {batch_size}개의 Head Nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 정의\n",
    "class SAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(SAGE, self).__init__()\n",
    "\n",
    "        self.num_layers = 2\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, adjs):\n",
    "        for i, (edge_index, _, size) in enumerate(adjs):\n",
    "            x_target = x[:size[1]]\n",
    "            x = self.convs[i]((x, x_target), edge_index)\n",
    "\n",
    "            if i != self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = F.dropout(x, p=0.5, training=self.training)\n",
    "        return x.log_softmax(dim=-1)\n",
    "\n",
    "    def inference(self, x_all):\n",
    "        pbar = tqdm(total=x_all.size(0) * self.num_layers)\n",
    "        pbar.set_description('Evaluating')\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            xs = []\n",
    "            for batch_size, n_id, adj in subgraph_loader:\n",
    "                edge_index, _, size = adj.to(device)\n",
    "                x = x_all[n_id].to(device)\n",
    "                x_target = x[:size[1]]\n",
    "                x = self.convs[i]((x, x_target), edge_index)\n",
    "                if i != self.num_layers - 1:\n",
    "                    x = F.relu(x)\n",
    "                xs.append(x.cpu())\n",
    "\n",
    "                pbar.update(batch_size)\n",
    "\n",
    "            x_all = torch.cat(xs, dim=0)\n",
    "\n",
    "        pbar.close()\n",
    "        return x_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SAGE(dataset.num_features, 256, dataset.num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=int(data.train_mask.sum()))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x[n_id], adjs)\n",
    "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_acc = total_correct / int(data.train_mask.sum())\n",
    "    return loss, approx_acc\n",
    "\n",
    "\n",
    "# 모델 평가\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model.inference(x)\n",
    "\n",
    "    y_true = y.cpu().unsqueeze(-1)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    results = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        results += [int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 153431/153431 [03:14<00:00, 790.65it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5166, Approx. Train: 0.9219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [07:19<00:00, 1061.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9550, Val: 0.9500, Test: 0.9484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 153431/153431 [03:12<00:00, 798.44it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.5452, Approx. Train: 0.9249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [07:16<00:00, 1068.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9583, Val: 0.9506, Test: 0.9503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 3):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a31a978b9b36123e657517a00f2bc515935c5b3db5200b3f6166774c20a94c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
