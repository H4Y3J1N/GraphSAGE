{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks with Pytorch\n",
    "\n",
    "Original Paper: https://arxiv.org/abs/1706.02216    \n",
    "Original Code: https://github.com/rusty1s/pytorch_geometric/blob/master/examples/reddit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch\n",
      "  Using cached pytorch-1.0.2.tar.gz (689 bytes)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.14.1-cp310-cp310-win_amd64.whl (1.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-0.13.1-cp310-cp310-win_amd64.whl (2.0 MB)\n",
      "Requirement already satisfied: requests in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (4.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.23.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.2.0)\n",
      "Requirement already satisfied: torch==1.13.1 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.14)\n",
      "Building wheels for collected packages: pytorch\n",
      "  Building wheel for pytorch (setup.py): started\n",
      "  Building wheel for pytorch (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for pytorch\n",
      "Failed to build pytorch\n",
      "Installing collected packages: pytorch, torchvision, torchaudio\n",
      "  Running setup.py install for pytorch: started\n",
      "  Running setup.py install for pytorch: finished with status 'error'\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\wikid\\AppData\\Local\\Temp\\pip-install-zgftp7g3\\pytorch_26602f29ae6b47ecab2b1c314f9b6d96\\setup.py\", line 15, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for pytorch\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for pytorch did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [6 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\wikid\\AppData\\Local\\Temp\\pip-install-zgftp7g3\\pytorch_26602f29ae6b47ecab2b1c314f9b6d96\\setup.py\", line 11, in <module>\n",
      "          raise Exception(message)\n",
      "      Exception: You tried to install \"pytorch\". The package named for PyTorch is \"torch\"\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> pytorch\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch_scatter in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.1.0)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Requirement already satisfied: torch_sparse in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.6.16)\n",
      "Requirement already satisfied: scipy in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch_sparse) (1.8.1)\n",
      "Requirement already satisfied: numpy<1.25.0,>=1.17.3 in c:\\users\\wikid\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from scipy->torch_sparse) (1.23.1)\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 23.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch torchvision torchaudio\n",
    "!pip install torch_scatter\n",
    "!pip install torch_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.datasets import Reddit\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "sys.path.append('./')\n",
    "from utils import *\n",
    "from model import *\n",
    "logger = make_logger(name='graphsage_logger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(os.getcwd(), '..', 'data', 'Reddit')\n",
    "dataset = Reddit(path)\n",
    "data = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_size = [25, 10]\n",
    "subgraph_loader_size = [-1]\n",
    "num_worker = 8\n",
    "epoch_num = 6\n",
    "batch = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 20:06:06,185 - graphsage_logger - Node Feature Matrix Info: # Nodes: 232965, # Node Features: 602\n",
      "2023-03-09 20:06:06,187 - graphsage_logger - Edge Index Shape: torch.Size([2, 114615892])\n",
      "2023-03-09 20:06:06,188 - graphsage_logger - Edge Weight: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153431\n"
     ]
    }
   ],
   "source": [
    "logger.info(f\"Node Feature Matrix Info: # Nodes: {data.x.shape[0]}, # Node Features: {data.x.shape[1]}\")\n",
    "\n",
    "logger.info(f\"Edge Index Shape: {data.edge_index.shape}\")\n",
    "logger.info(f\"Edge Weight: {data.edge_attr}\")\n",
    "\n",
    "print(data.train_mask.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\wikid\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch_geometric\\deprecation.py:12: UserWarning: 'data.NeighborSampler' is deprecated, use 'loader.NeighborSampler' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "train_loader = NeighborSampler(\n",
    "    data.edge_index, node_idx=data.train_mask,\n",
    "    sizes=train_loader_size, batch_size=batch, shuffle=True, num_workers=num_worker)\n",
    "\n",
    "subgraph_loader = NeighborSampler(\n",
    "    data.edge_index, node_idx=None,\n",
    "    sizes=subgraph_loader_size, batch_size=batch, shuffle=False, num_workers=num_worker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-09 20:07:48,346 - graphsage_logger - Current Batch Size: 1024\n",
      "2023-03-09 20:07:48,349 - graphsage_logger - 현재 Subgraph에서 사용된 모든 node id의 개수: 107146\n",
      "2023-03-09 20:07:48,350 - graphsage_logger - Layer의 수: 2\n",
      "2023-03-09 20:07:48,351 - graphsage_logger - 진행 방향: 85205개의 2-hop neighbors ->20917개의 1-hop neighbors -> 1024개의 Head Nodes\n"
     ]
    }
   ],
   "source": [
    "batch_size, n_id, adjs = next(iter(train_loader))\n",
    "\n",
    "logger.info(f\"Current Batch Size: {batch_size}\")\n",
    "logger.info(f\"현재 Subgraph에서 사용된 모든 node id의 개수: {n_id.shape[0]}\")\n",
    "logger.info(f\"Layer의 수: {len(adjs)}\")\n",
    "\n",
    "A = adjs[1].size[0] - batch_size\n",
    "B = adjs[0].size[0] - A - batch_size\n",
    "\n",
    "logger.info(f\"진행 방향: {B}개의 2-hop neighbors ->\"\n",
    "            f\"{A}개의 1-hop neighbors -> {batch_size}개의 Head Nodes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GraphSAGE(dataset.num_features, 256, dataset.num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "scheduler = StepLR(optimizer, step_size=2, gamma=0.1)\n",
    "\n",
    "x = data.x.to(device)\n",
    "y = data.y.squeeze().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=int(data.train_mask.sum()))\n",
    "    pbar.set_description(f'Epoch {epoch:02d}')\n",
    "\n",
    "    total_loss = total_correct = 0\n",
    "    for batch_size, n_id, adjs in train_loader:\n",
    "        adjs = [adj.to(device) for adj in adjs]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x[n_id], adjs)\n",
    "        loss = F.nll_loss(out, y[n_id[:batch_size]])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        total_correct += int(out.argmax(dim=-1).eq(y[n_id[:batch_size]]).sum())\n",
    "        pbar.update(batch_size)\n",
    "\n",
    "    pbar.close()\n",
    "\n",
    "    loss = total_loss / len(train_loader)\n",
    "    approx_acc = total_correct / int(data.train_mask.sum())\n",
    "    return loss, approx_acc\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    out = model.inference(x, subgraph_loader, device)\n",
    "\n",
    "    y_true = y.cpu().unsqueeze(-1)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "\n",
    "    results = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        results += [int(y_pred[mask].eq(y_true[mask]).sum()) / int(mask.sum())]\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for epoch in range(1, epoch_num):\n",
    "#     loss, acc = train(epoch)\n",
    "#     print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "#     scheduler.step()\n",
    "#     train_acc, val_acc, test_acc = test()\n",
    "#     print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 01: 100%|██████████| 153431/153431 [03:11<00:00, 801.66it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01, Loss: 0.5285, Approx. Train: 0.8914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [07:24<00:00, 1048.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9518, Val: 0.9496, Test: 0.9501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 02: 100%|██████████| 153431/153431 [03:38<00:00, 701.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02, Loss: 0.3871, Approx. Train: 0.9257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [07:25<00:00, 1046.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9548, Val: 0.9507, Test: 0.9498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 03: 100%|██████████| 153431/153431 [02:56<00:00, 868.61it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03, Loss: 0.2849, Approx. Train: 0.9419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [06:38<00:00, 1169.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9672, Val: 0.9604, Test: 0.9593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 04: 100%|██████████| 153431/153431 [03:06<00:00, 821.31it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04, Loss: 0.2238, Approx. Train: 0.9496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [06:38<00:00, 1168.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9705, Val: 0.9611, Test: 0.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 05: 100%|██████████| 153431/153431 [03:00<00:00, 850.57it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05, Loss: 0.1985, Approx. Train: 0.9529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [06:34<00:00, 1181.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9712, Val: 0.9624, Test: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 06: 100%|██████████| 153431/153431 [03:02<00:00, 841.23it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06, Loss: 0.1919, Approx. Train: 0.9542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [06:36<00:00, 1175.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.9716, Val: 0.9624, Test: 0.9617\n",
      "Best validation accuracy of 0.9624 was achieved at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 465930/465930 [06:35<00:00, 1179.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy of 0.9716 was achieved at epoch 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_val_acc = 0\n",
    "best_model = None\n",
    "best_epoch = 0\n",
    "patience = 2\n",
    "counter = 0\n",
    "\n",
    "for epoch in range(1, epoch_num+1):\n",
    "    loss, acc = train(epoch)\n",
    "    print(f'Epoch {epoch:02d}, Loss: {loss:.4f}, Approx. Train: {acc:.4f}')\n",
    "    scheduler.step()\n",
    "    \n",
    "    train_acc, val_acc, test_acc = test()\n",
    "    print(f'Train: {train_acc:.4f}, Val: {val_acc:.4f}, Test: {test_acc:.4f}')\n",
    "\n",
    "    # Early Stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_epoch = epoch\n",
    "        best_model = model.state_dict()\n",
    "        counter = 0\n",
    "    else:\n",
    "        counter += 1\n",
    "        if counter >= patience:\n",
    "            print(f'Early stopping: validation accuracy did not improve for {patience} epochs.')\n",
    "            break\n",
    "\n",
    "print(f'Best validation accuracy of {best_val_acc:.4f} was achieved at epoch {best_epoch}.')\n",
    "model.load_state_dict(best_model)\n",
    "test_acc = test()\n",
    "print(f'Test accuracy of {test_acc[0]:.4f} was achieved at epoch {best_epoch}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(best_model, 'best_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a31a978b9b36123e657517a00f2bc515935c5b3db5200b3f6166774c20a94c04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
